---
layout: default 
title: "Introducing ALFRED"
date: 2025-05-27 15:00:00 +0100 # Date and time of publication
author: "Suyash Agarwal" # Optional
categories: [AI, research, data science] # Optional
tags: [LLMs, APIs] # Optional
---

## ALFRED

I recently released an LLM-powered tool for automatic data analysis called Alfred. You can upload data to Alfred and the tool will do the following:
- generate some possible analysis steps to help you understand the data better
- generate some Python code that executes these analyses and produces some figures / text output
- run this code on your data in a sandboxed Python environment
- interpret the results of the analysis, update its understanding of your data and propose steps for further analysis
all in one click!

If you're interested in trying it out, [you can do so here](https://alfredthescientist.com/). This doesn't require any computing power/knowledge/setup. You can make an account or use Google to sign in. Please feel free to send me [feedback](https://forms.gle/tB23TinjsMxw6Re69) if you try it out! I'm happy to add features if they make the tool more useful. It's been fantastic to see Alfred speed up data analysis pipelines and I hope it can save your time and brainpower for more interesting things than writing Python code.

### Getting started

Once you sign in, you will see the Setup page. Here, you select which model you want to use from the following:
- Claude 4 Sonnet
- Gemini 2.5 Pro
- OpenAI o1
- OpenAI GPT-4.1

My basic advice is that Claude is the best model to use with Alfred. Gemini is similarly smart, but the API rate is quite severely limited to the point that it's difficult to get much use out of it. The OpenAI models are pretty robust but o1 is less ambitious than Claude with the analyses it tries to do, and GPT-4.1 is definitely a step down in intelligence (though it is very fast). 

Next, you need to give Alfred some data to work with. You can upload your own data in a variety of file formats. If your particular file format isn't supported (which you will know because you won't have the option to upload those files), then let me know and I can probably add it. Similarly, if your analysis involves a particular Python module that Alfred cannot access, I am more than happy to add it.

If you just want to see how Alfred works without using your own data, you can select ‘Use auto-generated test data’. This just loads a simple mixture of 3D Gaussians and Alfred will try and figure out what the data is. Finally, if you want to access publicly available data, you can do so by adding your own initial prompt. There is a specific option for IBL (International Brain Lab) data as we have written a special prompt for this. It takes a little while to run IBL code as this involves 
loading data from the ONE API.

Finally, you will want to add an initial prompt that explains what your data is, and what you want to get out of the analysis. This gives Alfred some context. You don't need to tell it things like the overall shape of the data (e.g. dimensions of numpy arrays) as Alfred will get this information on its own when it processes your data.


### Crunching data

Once you've started your analysis session, you will see the conversation window. This is where the iterative data analysis workflow takes place. Initially, Alfred will just give you an idea of what it plans to do to get an idea of the dataset before diving into proper analysis. On each iteration, you essentially have two options, Chat and Analyse:
- Use Chat when you want to interact with Alfred via text without asking it to generate code, e.g. if you want to correct it on something or give additional context/questions. Alfred will respond to you with text.
- Use Analyse when you want Alfred to go ahead with whatever the last agreed analysis step was. It will then generate code (which you will be able to see), execute it, analyse the results and show you its interpretation of the results. This 
works regardless of whether or not you entered text. If you enter text into the chat area and then press Analyse, Alfred will listen to whatever you said but won’t respond - it will just continue with code generation.

The idea is to keep the human in the loop, so the AI does one thing at a time under 
human supervision. 

If a particular LLM is overloaded or not working for any reason (e.g. you hit a token rate 
limit), you can switch models mid-session without losing any progress.

You can save an analysis session when you’re done, including all figures, the conversation history and separate Python files for each analysis iteration. 
Alfred is best used for exploratory analysis as you can rapidly generate lots of interesting views of your data if you don’t know what it is. You can also describe specific analyses in plain English and Alfred can generally do them, potentially saving you lots of time! Just make sure to read through AI-generated code as it can contain mistakes. 


Happy data analysis!
